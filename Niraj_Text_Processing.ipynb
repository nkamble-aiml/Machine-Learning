{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL1v6GDFGEMLcceI1LgFoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkamble-aiml/Machine-Learning/blob/main/Niraj_Text_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the libraries\n"
      ],
      "metadata": {
        "id": "WB7q7vWLOjCY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP4htBAVJmxN",
        "outputId": "a6b92806-502b-40f6-df03-6e07e4fa9955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt')        # For tokenization\n",
        "nltk.download('stopwords')    # For stop words\n",
        "nltk.download('wordnet')      # For lemmatization\n",
        "nltk.download('averaged_perceptron_tagger') # For POS tagging\n",
        "nltk.download('omw-1.4')      # For WordNet data\n",
        "nltk.download('punkt_tab')    # Download the missing resource for sentence tokenization\n",
        "\n",
        "\n",
        "# Download spaCy model\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text\n",
        "\n",
        "1.   **Normalization - Lower case**\n",
        "2.   Remove unwanted noise\n",
        "2.1  URL\n",
        "2.2  Remove Special symbol/character/punctuation\n",
        "2.3  More space with one space\n",
        "2.4  Stop words\n",
        "\n",
        "\n",
        "**3. Tokenization**\n",
        "3.1 Lemma/Stema\n",
        "\n",
        "**4. Counter/TF-IDF**\n",
        "\n",
        "**5. POS ( Part of Speech )**\n",
        "**6. ENTITY**\n",
        "     "
      ],
      "metadata": {
        "id": "ubbIQPFYPGBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sample text representing a part of a document\n",
        "sample_document = \"\"\"\n",
        "Machine learning (ML) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. Algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
        "\n",
        "Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. Mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\n",
        "\n",
        "In its application across business problems, machine learning is also referred to as predictive analytics.\n",
        "\"\"\"\n",
        "\n",
        "noisy_text = \"\"\"\n",
        "Machine learning rocks! It's revolutionizing the world in 2023 (and beyond!).\n",
        "Visit our site: http://example.com for more info.\n",
        "This is awesome!!! We collected 1,234 data points.\n",
        "Softbank and Google are major players.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zy_dEJdXO-3T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_raw_text = sample_document + \"\\n\" + noisy_text\n",
        "combined_raw_text"
      ],
      "metadata": {
        "id": "t8JtJATgRxca",
        "outputId": "7d62dc4b-0b96-408b-ad5f-0bf1884ae60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMachine learning (ML) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. Algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\\n\\nMachine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. Mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\\n\\nIn its application across business problems, machine learning is also referred to as predictive analytics.\\n\\n\\nMachine learning rocks! It\\'s revolutionizing the world in 2023 (and beyond!).\\nVisit our site: http://example.com for more info.\\nThis is awesome!!! We collected 1,234 data points.\\nSoftbank and Google are major players.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_raw_text = combined_raw_text.lower()\n",
        "combined_raw_text\n"
      ],
      "metadata": {
        "id": "CdtTo8mDSHG3",
        "outputId": "bce7ef9b-a562-4a61-f67a-b7ec601541d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmachine learning (ml) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\\n\\nmachine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. mathematical optimization delivers methods, theory and application domains to the field of machine learning. data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\\n\\nin its application across business problems, machine learning is also referred to as predictive analytics.\\n\\n\\nmachine learning rocks! it\\'s revolutionizing the world in 2023 (and beyond!).\\nvisit our site: http://example.com for more info.\\nthis is awesome!!! we collected 1,234 data points.\\nsoftbank and google are major players.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove url\n",
        "import re\n",
        "url_pattern = \"\"\n",
        "def removeURL(text):\n",
        "    url_pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    removed_url = url_pattern.sub(\"\",combined_raw_text)\n",
        "    return removed_url\n",
        "\n",
        "combined_raw_text_norm = removeURL(combined_raw_text)\n",
        "combined_raw_text_norm"
      ],
      "metadata": {
        "id": "L8XIepNrSQAV",
        "outputId": "6e5c16d7-0a8e-4362-d56b-d687c183378c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmachine learning (ml) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\\n\\nmachine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. mathematical optimization delivers methods, theory and application domains to the field of machine learning. data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\\n\\nin its application across business problems, machine learning is also referred to as predictive analytics.\\n\\n\\nmachine learning rocks! it\\'s revolutionizing the world in 2023 (and beyond!).\\nvisit our site:  for more info.\\nthis is awesome!!! we collected 1,234 data points.\\nsoftbank and google are major players.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeDigit(text):\n",
        "    pattern = r\"\\d+\"\n",
        "    removed_digit = re.sub(pattern,\"\",text)\n",
        "    return removed_digit\n",
        "\n",
        "combined_raw_text_norm = removeDigit(combined_raw_text_norm)\n",
        "combined_raw_text_norm"
      ],
      "metadata": {
        "id": "hQ0IG7OpTOt_",
        "outputId": "2cae841e-ec62-4e37-c041-3dab11421843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmachine learning (ml) is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.\\n\\nmachine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers. mathematical optimization delivers methods, theory and application domains to the field of machine learning. data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.\\n\\nin its application across business problems, machine learning is also referred to as predictive analytics.\\n\\n\\nmachine learning rocks! it\\'s revolutionizing the world in  (and beyond!).\\nvisit our site:  for more info.\\nthis is awesome!!! we collected , data points.\\nsoftbank and google are major players.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k87ItdWZdxow"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation\n",
        "\n",
        "#trans = str.maketrans(\"aeiou\",\"12345\")\n",
        "\n",
        "#\"education\".translate(trans)\n",
        "special_sym = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
        "\n",
        "print(string.punctuation)\n",
        "def removeSpecialCharacter(text):\n",
        "  trans = str.maketrans(\"\",\"\",special_sym)\n",
        "  return text.translate(trans)\n",
        "\n",
        "combined_raw_text_norm = removeSpecialCharacter(combined_raw_text_norm)\n",
        "print(combined_raw_text_norm )"
      ],
      "metadata": {
        "id": "K0no3KWwTWUL",
        "outputId": "e516549b-d6f7-46f0-e042-56cda4421c12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "\n",
            "machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
            "\n",
            "machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers. mathematical optimization delivers methods theory and application domains to the field of machine learning. data mining is a related field of study focusing on exploratory data analysis through unsupervised learning.\n",
            "\n",
            "in its application across business problems machine learning is also referred to as predictive analytics.\n",
            "\n",
            "\n",
            "machine learning rocks its revolutionizing the world in  and beyond.\n",
            "visit our site  for more info.\n",
            "this is awesome we collected  data points.\n",
            "softbank and google are major players.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeSpaces(text):\n",
        "  return re.sub(r\"\\s+\",\" \",text)\n",
        "\n",
        "combined_raw_text_norm = removeSpaces(combined_raw_text_norm)\n",
        "print(combined_raw_text_norm)"
      ],
      "metadata": {
        "id": "Ev384cwCV4l_",
        "outputId": "7cee7ad1-6752-4338-d5ad-640be132cdff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data. algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task. machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks. a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers. mathematical optimization delivers methods theory and application domains to the field of machine learning. data mining is a related field of study focusing on exploratory data analysis through unsupervised learning. in its application across business problems machine learning is also referred to as predictive analytics. machine learning rocks its revolutionizing the world in and beyond. visit our site for more info. this is awesome we collected data points. softbank and google are major players. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy\n",
        "# Load the small English spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spacy_norm = nlp(combined_raw_text_norm)\n",
        "\n",
        "print(\"========== Sentences ==================\")\n",
        "print(\"\\n\")\n",
        "for sent in spacy_norm.sents:\n",
        "  print(sent)\n",
        "print(\"\\n\")\n",
        "print(\"========== Words ==================\")\n",
        "print(\"\\n\")\n",
        "\n",
        "spacy_sentences = [sent.text for sent in spacy_norm.sents]\n",
        "print(\"\\n--- Sentence Tokenization (spaCy) ---\")\n",
        "for i, sentence in enumerate(spacy_sentences):\n",
        "    print(f\"Sentence {i+1}: {sentence}\")\n"
      ],
      "metadata": {
        "id": "eSIhZF6NXR3q",
        "outputId": "1008cd77-330f-48f8-ae4a-7417017545e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Sentences ==================\n",
            "\n",
            "\n",
            " machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data.\n",
            "algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
            "machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.\n",
            "a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers.\n",
            "mathematical optimization delivers methods theory and application domains to the field of machine learning.\n",
            "data mining is a related field of study focusing on exploratory data analysis through unsupervised learning.\n",
            "in its application across business problems machine learning is also referred to as predictive analytics.\n",
            "machine learning rocks its revolutionizing the world in and beyond.\n",
            "visit our site for more info.\n",
            "this is awesome we collected data points.\n",
            "softbank and google are major players.\n",
            "\n",
            "\n",
            "========== Words ==================\n",
            "\n",
            "\n",
            "\n",
            "--- Sentence Tokenization (spaCy) ---\n",
            "Sentence 1:  machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data.\n",
            "Sentence 2: algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
            "Sentence 3: machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.\n",
            "Sentence 4: a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers.\n",
            "Sentence 5: mathematical optimization delivers methods theory and application domains to the field of machine learning.\n",
            "Sentence 6: data mining is a related field of study focusing on exploratory data analysis through unsupervised learning.\n",
            "Sentence 7: in its application across business problems machine learning is also referred to as predictive analytics.\n",
            "Sentence 8: machine learning rocks its revolutionizing the world in and beyond.\n",
            "Sentence 9: visit our site for more info.\n",
            "Sentence 10: this is awesome we collected data points.\n",
            "Sentence 11: softbank and google are major players.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### FINDING WORDS in SENTENCES\n",
        "spacy_norm_words = [ token.text for token in spacy_norm if token.is_stop == False]\n",
        "\n",
        "spacy_norm_words = [word for word in spacy_norm_words if word not in \".\"]\n",
        "spacy_norm_words"
      ],
      "metadata": {
        "id": "Y2DGNvmFe_w1",
        "outputId": "e39f0d77-be0a-43c9-c75e-1208a183c5cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'ml',\n",
              " 'field',\n",
              " 'study',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'concerned',\n",
              " 'development',\n",
              " 'computer',\n",
              " 'algorithms',\n",
              " 'learn',\n",
              " 'predictions',\n",
              " 'data',\n",
              " 'algorithms',\n",
              " 'build',\n",
              " 'mathematical',\n",
              " 'model',\n",
              " 'based',\n",
              " 'sample',\n",
              " 'data',\n",
              " 'known',\n",
              " 'training',\n",
              " 'data',\n",
              " 'order',\n",
              " 'predictions',\n",
              " 'decisions',\n",
              " 'explicitly',\n",
              " 'programmed',\n",
              " 'perform',\n",
              " 'task',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'algorithms',\n",
              " 'wide',\n",
              " 'variety',\n",
              " 'applications',\n",
              " 'email',\n",
              " 'filtering',\n",
              " 'computer',\n",
              " 'vision',\n",
              " 'difficult',\n",
              " 'infeasible',\n",
              " 'develop',\n",
              " 'conventional',\n",
              " 'algorithms',\n",
              " 'perform',\n",
              " 'needed',\n",
              " 'tasks',\n",
              " 'subset',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'closely',\n",
              " 'related',\n",
              " 'computational',\n",
              " 'statistics',\n",
              " 'focuses',\n",
              " 'making',\n",
              " 'predictions',\n",
              " 'computers',\n",
              " 'mathematical',\n",
              " 'optimization',\n",
              " 'delivers',\n",
              " 'methods',\n",
              " 'theory',\n",
              " 'application',\n",
              " 'domains',\n",
              " 'field',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'data',\n",
              " 'mining',\n",
              " 'related',\n",
              " 'field',\n",
              " 'study',\n",
              " 'focusing',\n",
              " 'exploratory',\n",
              " 'data',\n",
              " 'analysis',\n",
              " 'unsupervised',\n",
              " 'learning',\n",
              " 'application',\n",
              " 'business',\n",
              " 'problems',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'referred',\n",
              " 'predictive',\n",
              " 'analytics',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'rocks',\n",
              " 'revolutionizing',\n",
              " 'world',\n",
              " 'visit',\n",
              " 'site',\n",
              " 'info',\n",
              " 'awesome',\n",
              " 'collected',\n",
              " 'data',\n",
              " 'points',\n",
              " 'softbank',\n",
              " 'google',\n",
              " 'major',\n",
              " 'players']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### counting number of words"
      ],
      "metadata": {
        "id": "94iiNJ8-ic8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter = Counter(spacy_norm_words)\n",
        "counter"
      ],
      "metadata": {
        "id": "hNTMcZpfif41",
        "outputId": "6ee2f25e-8c0c-44ec-8fbb-e5fbd7897504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({' ': 1,\n",
              "         'machine': 6,\n",
              "         'learning': 7,\n",
              "         'ml': 1,\n",
              "         'field': 3,\n",
              "         'study': 2,\n",
              "         'artificial': 1,\n",
              "         'intelligence': 1,\n",
              "         'concerned': 1,\n",
              "         'development': 1,\n",
              "         'computer': 2,\n",
              "         'algorithms': 4,\n",
              "         'learn': 1,\n",
              "         'predictions': 3,\n",
              "         'data': 6,\n",
              "         'build': 1,\n",
              "         'mathematical': 2,\n",
              "         'model': 1,\n",
              "         'based': 1,\n",
              "         'sample': 1,\n",
              "         'known': 1,\n",
              "         'training': 1,\n",
              "         'order': 1,\n",
              "         'decisions': 1,\n",
              "         'explicitly': 1,\n",
              "         'programmed': 1,\n",
              "         'perform': 2,\n",
              "         'task': 1,\n",
              "         'wide': 1,\n",
              "         'variety': 1,\n",
              "         'applications': 1,\n",
              "         'email': 1,\n",
              "         'filtering': 1,\n",
              "         'vision': 1,\n",
              "         'difficult': 1,\n",
              "         'infeasible': 1,\n",
              "         'develop': 1,\n",
              "         'conventional': 1,\n",
              "         'needed': 1,\n",
              "         'tasks': 1,\n",
              "         'subset': 1,\n",
              "         'closely': 1,\n",
              "         'related': 2,\n",
              "         'computational': 1,\n",
              "         'statistics': 1,\n",
              "         'focuses': 1,\n",
              "         'making': 1,\n",
              "         'computers': 1,\n",
              "         'optimization': 1,\n",
              "         'delivers': 1,\n",
              "         'methods': 1,\n",
              "         'theory': 1,\n",
              "         'application': 2,\n",
              "         'domains': 1,\n",
              "         'mining': 1,\n",
              "         'focusing': 1,\n",
              "         'exploratory': 1,\n",
              "         'analysis': 1,\n",
              "         'unsupervised': 1,\n",
              "         'business': 1,\n",
              "         'problems': 1,\n",
              "         'referred': 1,\n",
              "         'predictive': 1,\n",
              "         'analytics': 1,\n",
              "         'rocks': 1,\n",
              "         'revolutionizing': 1,\n",
              "         'world': 1,\n",
              "         'visit': 1,\n",
              "         'site': 1,\n",
              "         'info': 1,\n",
              "         'awesome': 1,\n",
              "         'collected': 1,\n",
              "         'points': 1,\n",
              "         'softbank': 1,\n",
              "         'google': 1,\n",
              "         'major': 1,\n",
              "         'players': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "spacy_norm_sentence = [sent.text for sent in spacy_norm.sents]\n",
        "print(spacy_norm_sentence)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "countVect = CountVectorizer()\n",
        "bow = countVect.fit_transform(spacy_norm_sentence)\n",
        "print( bow.toarray()[:20])\n",
        "print( countVect.get_feature_names_out())\n",
        "df_bow = pd.DataFrame(bow.toarray(),columns=countVect.get_feature_names_out())\n",
        "df_bow"
      ],
      "metadata": {
        "id": "LLbw6rtait3c",
        "outputId": "94f75d3c-ef9d-4341-f016-535a58db28b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' machine learning ml is a field of study in artificial intelligence concerned with the development of computer algorithms that can learn from and make predictions on data.', 'algorithms build a mathematical model based on sample data known as training data in order to make predictions or decisions without being explicitly programmed to perform the task.', 'machine learning algorithms are used in a wide variety of applications such as email filtering and computer vision where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.', 'a subset of machine learning is closely related to computational statistics which focuses on making predictions using computers.', 'mathematical optimization delivers methods theory and application domains to the field of machine learning.', 'data mining is a related field of study focusing on exploratory data analysis through unsupervised learning.', 'in its application across business problems machine learning is also referred to as predictive analytics.', 'machine learning rocks its revolutionizing the world in and beyond.', 'visit our site for more info.', 'this is awesome we collected data points.', 'softbank and google are major players.']\n",
            "\n",
            "\n",
            "[[0 1 0 ... 1 0 0]\n",
            " [0 1 0 ... 0 1 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "['across' 'algorithms' 'also' 'analysis' 'analytics' 'and' 'application'\n",
            " 'applications' 'are' 'artificial' 'as' 'awesome' 'based' 'being' 'beyond'\n",
            " 'build' 'business' 'can' 'closely' 'collected' 'computational' 'computer'\n",
            " 'computers' 'concerned' 'conventional' 'data' 'decisions' 'delivers'\n",
            " 'develop' 'development' 'difficult' 'domains' 'email' 'explicitly'\n",
            " 'exploratory' 'field' 'filtering' 'focuses' 'focusing' 'for' 'from'\n",
            " 'google' 'in' 'infeasible' 'info' 'intelligence' 'is' 'it' 'its' 'known'\n",
            " 'learn' 'learning' 'machine' 'major' 'make' 'making' 'mathematical'\n",
            " 'methods' 'mining' 'ml' 'model' 'more' 'needed' 'of' 'on' 'optimization'\n",
            " 'or' 'order' 'our' 'perform' 'players' 'points' 'predictions'\n",
            " 'predictive' 'problems' 'programmed' 'referred' 'related'\n",
            " 'revolutionizing' 'rocks' 'sample' 'site' 'softbank' 'statistics' 'study'\n",
            " 'subset' 'such' 'task' 'tasks' 'that' 'the' 'theory' 'this' 'through'\n",
            " 'to' 'training' 'unsupervised' 'used' 'using' 'variety' 'vision' 'visit'\n",
            " 'we' 'where' 'which' 'wide' 'with' 'without' 'world']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    across  algorithms  also  analysis  analytics  and  application  \\\n",
              "0        0           1     0         0          0    1            0   \n",
              "1        0           1     0         0          0    0            0   \n",
              "2        0           2     0         0          0    1            0   \n",
              "3        0           0     0         0          0    0            0   \n",
              "4        0           0     0         0          0    1            1   \n",
              "5        0           0     0         1          0    0            0   \n",
              "6        1           0     1         0          1    0            1   \n",
              "7        0           0     0         0          0    1            0   \n",
              "8        0           0     0         0          0    0            0   \n",
              "9        0           0     0         0          0    0            0   \n",
              "10       0           0     0         0          0    1            0   \n",
              "\n",
              "    applications  are  artificial  ...  variety  vision  visit  we  where  \\\n",
              "0              0    0           1  ...        0       0      0   0      0   \n",
              "1              0    0           0  ...        0       0      0   0      0   \n",
              "2              1    1           0  ...        1       1      0   0      1   \n",
              "3              0    0           0  ...        0       0      0   0      0   \n",
              "4              0    0           0  ...        0       0      0   0      0   \n",
              "5              0    0           0  ...        0       0      0   0      0   \n",
              "6              0    0           0  ...        0       0      0   0      0   \n",
              "7              0    0           0  ...        0       0      0   0      0   \n",
              "8              0    0           0  ...        0       0      1   0      0   \n",
              "9              0    0           0  ...        0       0      0   1      0   \n",
              "10             0    1           0  ...        0       0      0   0      0   \n",
              "\n",
              "    which  wide  with  without  world  \n",
              "0       0     0     1        0      0  \n",
              "1       0     0     0        1      0  \n",
              "2       0     1     0        0      0  \n",
              "3       1     0     0        0      0  \n",
              "4       0     0     0        0      0  \n",
              "5       0     0     0        0      0  \n",
              "6       0     0     0        0      0  \n",
              "7       0     0     0        0      1  \n",
              "8       0     0     0        0      0  \n",
              "9       0     0     0        0      0  \n",
              "10      0     0     0        0      0  \n",
              "\n",
              "[11 rows x 109 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb3bf0c6-8ccb-4c6e-83c8-cb2fae89a23e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>across</th>\n",
              "      <th>algorithms</th>\n",
              "      <th>also</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analytics</th>\n",
              "      <th>and</th>\n",
              "      <th>application</th>\n",
              "      <th>applications</th>\n",
              "      <th>are</th>\n",
              "      <th>artificial</th>\n",
              "      <th>...</th>\n",
              "      <th>variety</th>\n",
              "      <th>vision</th>\n",
              "      <th>visit</th>\n",
              "      <th>we</th>\n",
              "      <th>where</th>\n",
              "      <th>which</th>\n",
              "      <th>wide</th>\n",
              "      <th>with</th>\n",
              "      <th>without</th>\n",
              "      <th>world</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 109 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb3bf0c6-8ccb-4c6e-83c8-cb2fae89a23e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb3bf0c6-8ccb-4c6e-83c8-cb2fae89a23e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb3bf0c6-8ccb-4c6e-83c8-cb2fae89a23e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bc8c5110-8dfd-4b42-8901-f3150133c012\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc8c5110-8dfd-4b42-8901-f3150133c012')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bc8c5110-8dfd-4b42-8901-f3150133c012 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f755641a-4883-426f-835f-b6ed55d591ba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_bow')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f755641a-4883-426f-835f-b6ed55d591ba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_bow');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_bow"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tfidVect = TfidfVectorizer()\n",
        "tfid = tfidVect.fit_transform(spacy_norm_sentence)\n",
        "print( tfid.toarray()[:20])\n",
        "print( tfidVect.get_feature_names_out())\n",
        "df_tfid = pd.DataFrame(tfid.toarray(),columns=tfidVect.get_feature_names_out())\n",
        "df_tfid.head(20)"
      ],
      "metadata": {
        "id": "Qu9kSpbmnGn_",
        "outputId": "43c20f1d-fca2-4ced-c4fd-0cb862744751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.17608108 0.         ... 0.23423861 0.         0.        ]\n",
            " [0.         0.15997189 0.         ... 0.         0.21280874 0.        ]\n",
            " [0.         0.29742313 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "['across' 'algorithms' 'also' 'analysis' 'analytics' 'and' 'application'\n",
            " 'applications' 'are' 'artificial' 'as' 'awesome' 'based' 'being' 'beyond'\n",
            " 'build' 'business' 'can' 'closely' 'collected' 'computational' 'computer'\n",
            " 'computers' 'concerned' 'conventional' 'data' 'decisions' 'delivers'\n",
            " 'develop' 'development' 'difficult' 'domains' 'email' 'explicitly'\n",
            " 'exploratory' 'field' 'filtering' 'focuses' 'focusing' 'for' 'from'\n",
            " 'google' 'in' 'infeasible' 'info' 'intelligence' 'is' 'it' 'its' 'known'\n",
            " 'learn' 'learning' 'machine' 'major' 'make' 'making' 'mathematical'\n",
            " 'methods' 'mining' 'ml' 'model' 'more' 'needed' 'of' 'on' 'optimization'\n",
            " 'or' 'order' 'our' 'perform' 'players' 'points' 'predictions'\n",
            " 'predictive' 'problems' 'programmed' 'referred' 'related'\n",
            " 'revolutionizing' 'rocks' 'sample' 'site' 'softbank' 'statistics' 'study'\n",
            " 'subset' 'such' 'task' 'tasks' 'that' 'the' 'theory' 'this' 'through'\n",
            " 'to' 'training' 'unsupervised' 'used' 'using' 'variety' 'vision' 'visit'\n",
            " 'we' 'where' 'which' 'wide' 'with' 'without' 'world']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      across  algorithms      also  analysis  analytics       and  \\\n",
              "0   0.000000    0.176081  0.000000  0.000000   0.000000  0.142061   \n",
              "1   0.000000    0.159972  0.000000  0.000000   0.000000  0.000000   \n",
              "2   0.000000    0.297423  0.000000  0.000000   0.000000  0.119980   \n",
              "3   0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
              "4   0.000000    0.000000  0.000000  0.000000   0.000000  0.201546   \n",
              "5   0.000000    0.000000  0.000000  0.298701   0.000000  0.000000   \n",
              "6   0.306812    0.000000  0.306812  0.000000   0.306812  0.000000   \n",
              "7   0.000000    0.000000  0.000000  0.000000   0.000000  0.239893   \n",
              "8   0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
              "9   0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
              "10  0.000000    0.000000  0.000000  0.000000   0.000000  0.268595   \n",
              "\n",
              "    application  applications       are  artificial  ...   variety    vision  \\\n",
              "0      0.000000      0.000000  0.000000    0.234239  ...  0.000000  0.000000   \n",
              "1      0.000000      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "2      0.000000      0.197829  0.169097    0.000000  ...  0.197829  0.197829   \n",
              "3      0.000000      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "4      0.284056      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "5      0.000000      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "6      0.262252      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "7      0.000000      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "8      0.000000      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "9      0.000000      0.000000  0.000000    0.000000  ...  0.000000  0.000000   \n",
              "10     0.000000      0.000000  0.378554    0.000000  ...  0.000000  0.000000   \n",
              "\n",
              "       visit        we     where     which      wide      with   without  \\\n",
              "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.234239  0.000000   \n",
              "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.212809   \n",
              "2   0.000000  0.000000  0.197829  0.000000  0.197829  0.000000  0.000000   \n",
              "3   0.000000  0.000000  0.000000  0.284626  0.000000  0.000000  0.000000   \n",
              "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "8   0.408248  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "9   0.000000  0.416841  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "      world  \n",
              "0   0.00000  \n",
              "1   0.00000  \n",
              "2   0.00000  \n",
              "3   0.00000  \n",
              "4   0.00000  \n",
              "5   0.00000  \n",
              "6   0.00000  \n",
              "7   0.39555  \n",
              "8   0.00000  \n",
              "9   0.00000  \n",
              "10  0.00000  \n",
              "\n",
              "[11 rows x 109 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5d24457-fecf-45f4-ab57-3a1a117e6dc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>across</th>\n",
              "      <th>algorithms</th>\n",
              "      <th>also</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analytics</th>\n",
              "      <th>and</th>\n",
              "      <th>application</th>\n",
              "      <th>applications</th>\n",
              "      <th>are</th>\n",
              "      <th>artificial</th>\n",
              "      <th>...</th>\n",
              "      <th>variety</th>\n",
              "      <th>vision</th>\n",
              "      <th>visit</th>\n",
              "      <th>we</th>\n",
              "      <th>where</th>\n",
              "      <th>which</th>\n",
              "      <th>wide</th>\n",
              "      <th>with</th>\n",
              "      <th>without</th>\n",
              "      <th>world</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.212809</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.297423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119980</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197829</td>\n",
              "      <td>0.169097</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.197829</td>\n",
              "      <td>0.197829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.284626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.201546</td>\n",
              "      <td>0.284056</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.306812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.262252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.239893</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.39555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.416841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.268595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.378554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 109 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5d24457-fecf-45f4-ab57-3a1a117e6dc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5d24457-fecf-45f4-ab57-3a1a117e6dc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5d24457-fecf-45f4-ab57-3a1a117e6dc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6bff8655-bf11-4a2f-8dff-e08f20bfad02\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bff8655-bf11-4a2f-8dff-e08f20bfad02')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6bff8655-bf11-4a2f-8dff-e08f20bfad02 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tfid"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_raw_text = nlp(combined_raw_text)\n",
        "for ent in spacy_raw_text.ents:\n",
        "  if ent.label_ in ['ORG', 'GPE', 'PERSON', 'DATE', 'CARDINAL', 'LOC']: # Filter for common entity types\n",
        "         print(f\"Entity: {ent.text}, Type: {ent.label_}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VWA6yVQM6F12",
        "outputId": "bd4e83de-c04a-401e-d256-5304e4cbd67d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: 2023, Type: DATE\n",
            "Entity: 1,234, Type: CARDINAL\n",
            "Entity: google, Type: ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in spacy_norm:\n",
        "  print(sent.text , \" \" , sent.pos_ , \" \" + sent.tag_)\n"
      ],
      "metadata": {
        "id": "fqKL9-uP8IaB",
        "outputId": "6cb1a5e0-cc29-46bb-d362-2dc985e3fa5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    SPACE  _SP\n",
            "machine   NOUN  NN\n",
            "learning   NOUN  NN\n",
            "ml   PROPN  NNP\n",
            "is   AUX  VBZ\n",
            "a   DET  DT\n",
            "field   NOUN  NN\n",
            "of   ADP  IN\n",
            "study   NOUN  NN\n",
            "in   ADP  IN\n",
            "artificial   ADJ  JJ\n",
            "intelligence   NOUN  NN\n",
            "concerned   VERB  VBN\n",
            "with   ADP  IN\n",
            "the   DET  DT\n",
            "development   NOUN  NN\n",
            "of   ADP  IN\n",
            "computer   NOUN  NN\n",
            "algorithms   NOUN  NNS\n",
            "that   PRON  WDT\n",
            "can   AUX  MD\n",
            "learn   VERB  VB\n",
            "from   ADP  IN\n",
            "and   CCONJ  CC\n",
            "make   VERB  VB\n",
            "predictions   NOUN  NNS\n",
            "on   ADP  IN\n",
            "data   NOUN  NNS\n",
            ".   PUNCT  .\n",
            "algorithms   NOUN  NNS\n",
            "build   VERB  VBP\n",
            "a   DET  DT\n",
            "mathematical   ADJ  JJ\n",
            "model   NOUN  NN\n",
            "based   VERB  VBN\n",
            "on   ADP  IN\n",
            "sample   NOUN  NN\n",
            "data   NOUN  NNS\n",
            "known   VERB  VBN\n",
            "as   ADP  IN\n",
            "training   VERB  VBG\n",
            "data   NOUN  NNS\n",
            "in   ADP  IN\n",
            "order   NOUN  NN\n",
            "to   PART  TO\n",
            "make   VERB  VB\n",
            "predictions   NOUN  NNS\n",
            "or   CCONJ  CC\n",
            "decisions   NOUN  NNS\n",
            "without   ADP  IN\n",
            "being   AUX  VBG\n",
            "explicitly   ADV  RB\n",
            "programmed   VERB  VBN\n",
            "to   PART  TO\n",
            "perform   VERB  VB\n",
            "the   DET  DT\n",
            "task   NOUN  NN\n",
            ".   PUNCT  .\n",
            "machine   NOUN  NN\n",
            "learning   VERB  VBG\n",
            "algorithms   NOUN  NNS\n",
            "are   AUX  VBP\n",
            "used   VERB  VBN\n",
            "in   ADP  IN\n",
            "a   DET  DT\n",
            "wide   ADJ  JJ\n",
            "variety   NOUN  NN\n",
            "of   ADP  IN\n",
            "applications   NOUN  NNS\n",
            "such   ADJ  JJ\n",
            "as   ADP  IN\n",
            "email   NOUN  NN\n",
            "filtering   NOUN  NN\n",
            "and   CCONJ  CC\n",
            "computer   NOUN  NN\n",
            "vision   NOUN  NN\n",
            "where   SCONJ  WRB\n",
            "it   PRON  PRP\n",
            "is   AUX  VBZ\n",
            "difficult   ADJ  JJ\n",
            "or   CCONJ  CC\n",
            "infeasible   ADJ  JJ\n",
            "to   PART  TO\n",
            "develop   VERB  VB\n",
            "conventional   ADJ  JJ\n",
            "algorithms   NOUN  NNS\n",
            "to   PART  TO\n",
            "perform   VERB  VB\n",
            "the   DET  DT\n",
            "needed   VERB  VBN\n",
            "tasks   NOUN  NNS\n",
            ".   PUNCT  .\n",
            "a   DET  DT\n",
            "subset   NOUN  NN\n",
            "of   ADP  IN\n",
            "machine   NOUN  NN\n",
            "learning   NOUN  NN\n",
            "is   AUX  VBZ\n",
            "closely   ADV  RB\n",
            "related   ADJ  JJ\n",
            "to   ADP  IN\n",
            "computational   ADJ  JJ\n",
            "statistics   NOUN  NNS\n",
            "which   PRON  WDT\n",
            "focuses   VERB  VBZ\n",
            "on   ADP  IN\n",
            "making   VERB  VBG\n",
            "predictions   NOUN  NNS\n",
            "using   VERB  VBG\n",
            "computers   NOUN  NNS\n",
            ".   PUNCT  .\n",
            "mathematical   ADJ  JJ\n",
            "optimization   NOUN  NN\n",
            "delivers   VERB  VBZ\n",
            "methods   NOUN  NNS\n",
            "theory   NOUN  NN\n",
            "and   CCONJ  CC\n",
            "application   NOUN  NN\n",
            "domains   NOUN  NNS\n",
            "to   ADP  IN\n",
            "the   DET  DT\n",
            "field   NOUN  NN\n",
            "of   ADP  IN\n",
            "machine   NOUN  NN\n",
            "learning   NOUN  NN\n",
            ".   PUNCT  .\n",
            "data   NOUN  NNS\n",
            "mining   NOUN  NN\n",
            "is   AUX  VBZ\n",
            "a   DET  DT\n",
            "related   ADJ  JJ\n",
            "field   NOUN  NN\n",
            "of   ADP  IN\n",
            "study   NOUN  NN\n",
            "focusing   VERB  VBG\n",
            "on   ADP  IN\n",
            "exploratory   ADJ  JJ\n",
            "data   NOUN  NNS\n",
            "analysis   NOUN  NN\n",
            "through   ADP  IN\n",
            "unsupervised   ADJ  JJ\n",
            "learning   NOUN  NN\n",
            ".   PUNCT  .\n",
            "in   ADP  IN\n",
            "its   PRON  PRP$\n",
            "application   NOUN  NN\n",
            "across   ADP  IN\n",
            "business   NOUN  NN\n",
            "problems   NOUN  NNS\n",
            "machine   NOUN  NN\n",
            "learning   NOUN  NN\n",
            "is   AUX  VBZ\n",
            "also   ADV  RB\n",
            "referred   VERB  VBN\n",
            "to   ADP  IN\n",
            "as   ADP  IN\n",
            "predictive   ADJ  JJ\n",
            "analytics   NOUN  NNS\n",
            ".   PUNCT  .\n",
            "machine   NOUN  NN\n",
            "learning   NOUN  NN\n",
            "rocks   VERB  VBZ\n",
            "its   PRON  PRP$\n",
            "revolutionizing   VERB  VBG\n",
            "the   DET  DT\n",
            "world   NOUN  NN\n",
            "in   ADP  IN\n",
            "and   CCONJ  CC\n",
            "beyond   ADP  IN\n",
            ".   PUNCT  .\n",
            "visit   VERB  VB\n",
            "our   PRON  PRP$\n",
            "site   NOUN  NN\n",
            "for   ADP  IN\n",
            "more   ADJ  JJR\n",
            "info   NOUN  NN\n",
            ".   PUNCT  .\n",
            "this   PRON  DT\n",
            "is   AUX  VBZ\n",
            "awesome   ADJ  JJ\n",
            "we   PRON  PRP\n",
            "collected   VERB  VBD\n",
            "data   NOUN  NN\n",
            "points   NOUN  NNS\n",
            ".   PUNCT  .\n",
            "softbank   PROPN  NNP\n",
            "and   CCONJ  CC\n",
            "google   PROPN  NNP\n",
            "are   AUX  VBP\n",
            "major   ADJ  JJ\n",
            "players   NOUN  NNS\n",
            ".   PUNCT  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shallow Parsing (Chunking)\n",
        "Shallow parsing, also known as chunking, groups words into meaningful phrases (like Noun Phrases, Verb Phrases) based on their POS tags. It adds more structure than just POS tagging but doesn't provide a full parse tree like constituency or dependency parsing."
      ],
      "metadata": {
        "id": "2cY-oI_i9neD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"--- Noun Chunking with spaCy ---\")\n",
        "for chunk in spacy_norm.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "metadata": {
        "id": "PpbwDKPB9LHv",
        "outputId": "8f6f5944-4c01-4845-8d29-34112f9ceffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Noun Chunking with spaCy ---\n",
            " machine learning ml\n",
            "a field\n",
            "study\n",
            "artificial intelligence\n",
            "the development\n",
            "computer algorithms\n",
            "that\n",
            "predictions\n",
            "data\n",
            "algorithms\n",
            "a mathematical model\n",
            "sample data\n",
            "data\n",
            "order\n",
            "predictions\n",
            "decisions\n",
            "the task\n",
            "machine learning algorithms\n",
            "a wide variety\n",
            "applications\n",
            "email filtering and computer vision\n",
            "it\n",
            "conventional algorithms\n",
            "the needed tasks\n",
            "a subset\n",
            "machine learning\n",
            "computational statistics\n",
            "which\n",
            "predictions\n",
            "computers\n",
            "mathematical optimization\n",
            "methods theory\n",
            "application domains\n",
            "the field\n",
            "machine learning\n",
            "data mining\n",
            "a related field\n",
            "study\n",
            "exploratory data analysis\n",
            "unsupervised learning\n",
            "its application\n",
            "business problems machine learning\n",
            "predictive analytics\n",
            "machine learning\n",
            "the world\n",
            "our site\n",
            "more info\n",
            "this\n",
            "we\n",
            "data points\n",
            "softbank\n",
            "google\n",
            "major players\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using spaCy to find noun chunks\n",
        "print(\"--- Noun Chunking with spaCy ---\")\n",
        "for chunk in spacy_norm.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "metadata": {
        "id": "9DnGRmGf9ZjJ",
        "outputId": "1a1822cd-2987-45ca-fbfb-6710b8c0bf06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Noun Chunking with spaCy ---\n",
            " machine learning ml\n",
            "a field\n",
            "study\n",
            "artificial intelligence\n",
            "the development\n",
            "computer algorithms\n",
            "that\n",
            "predictions\n",
            "data\n",
            "algorithms\n",
            "a mathematical model\n",
            "sample data\n",
            "data\n",
            "order\n",
            "predictions\n",
            "decisions\n",
            "the task\n",
            "machine learning algorithms\n",
            "a wide variety\n",
            "applications\n",
            "email filtering and computer vision\n",
            "it\n",
            "conventional algorithms\n",
            "the needed tasks\n",
            "a subset\n",
            "machine learning\n",
            "computational statistics\n",
            "which\n",
            "predictions\n",
            "computers\n",
            "mathematical optimization\n",
            "methods theory\n",
            "application domains\n",
            "the field\n",
            "machine learning\n",
            "data mining\n",
            "a related field\n",
            "study\n",
            "exploratory data analysis\n",
            "unsupervised learning\n",
            "its application\n",
            "business problems machine learning\n",
            "predictive analytics\n",
            "machine learning\n",
            "the world\n",
            "our site\n",
            "more info\n",
            "this\n",
            "we\n",
            "data points\n",
            "softbank\n",
            "google\n",
            "major players\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "N48KJLDkEXtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import nltk\n",
        "# analyzer\n",
        "# print the sentiment analysis ( Postive/negative/ neutral or emotion intensity)\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sentence_for_sentiment = \"Machine learning is a field of study in artificial intelligence.\"\n",
        "\n",
        "senitmentAnalyzer = SentimentIntensityAnalyzer()\n",
        "polScore = senitmentAnalyzer.polarity_scores(sentence_for_sentiment)\n",
        "print(polScore)"
      ],
      "metadata": {
        "id": "VSlrz6ajEbD3",
        "outputId": "1c9d7b87-c44e-4684-f90e-56b6dea29192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.721, 'pos': 0.279, 'compound': 0.4767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "doc[0].pos_\n",
        "doc[0].text\n",
        "doc[0].tag_"
      ],
      "metadata": {
        "id": "C7_Is3MM7zI8",
        "outputId": "8d75742d-507e-45df-b0bd-940aca241bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NNP'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Softbank invested $2.3 billion in India in 2023.\")\n",
        "for ent in doc.ents:\n",
        "  if ent.label_ in ['ORG', 'GPE', 'PERSON', 'DATE', 'CARDINAL', 'LOC','MONEY','CURRENCY']: # Filter for common entity types\n",
        "         print(f\"Entity: {ent.text}, Type: {ent.label_}\")"
      ],
      "metadata": {
        "id": "eQ9E9cOS8ChI",
        "outputId": "5b81166a-b316-4f14-e08e-f7d2d175071b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Softbank, Type: ORG\n",
            "Entity: $2.3 billion, Type: MONEY\n",
            "Entity: India, Type: GPE\n",
            "Entity: 2023, Type: DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Running runs ran was quick\")\n",
        "[token.lemma_ for token in doc]"
      ],
      "metadata": {
        "id": "c4Rq4DhVCSuu",
        "outputId": "eb68b6d6-e4ef-4429-bc5a-b6d73bbadcdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['run', 'run', 'run', 'be', 'quick']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "KRMWoCNL1_cA",
        "outputId": "08cc054b-dc30-4600-ef2e-b92e36a7b42c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "Z522cnx42FQB",
        "outputId": "817f498f-a91a-447b-ea73-c2b85c9fa952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q nrclex"
      ],
      "metadata": {
        "id": "uCot2bMC2K1v",
        "outputId": "10489899-f235-4f77-aac2-2a01e6becc5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/396.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/396.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/396.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nrclex (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "siX4gkJN2TFD",
        "outputId": "a675c778-0e80-46af-c6a2-1109ceb724c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "062f8df7a6ff49aaa2b4d170aaf69501"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from nrclex import NRCLex\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "#Importing necessary libraries\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "nltk.download('stopwords')\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "n8QsdqmI2Zyv",
        "outputId": "63e31159-0b2a-4393-91b7-c064ca6f58b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import spacy\n",
        "\n",
        "\n",
        "tweet = \"You are awesome!!!\"\n",
        "blob = TextBlob(tweet)\n",
        "print(blob.sentiment)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uDOM59P02f9O",
        "outputId": "34928eac-6a48-403a-e966-d3521550e9ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=1.0, subjectivity=1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The movie was a masterpiece, but too long and slightly boring in parts.\"\n",
        "blob = TextBlob(text)\n",
        "print(\"Polarity:\", blob.sentiment.polarity)\n",
        "print(\"Subjectivity:\", blob.sentiment.subjectivity)"
      ],
      "metadata": {
        "id": "RwUudgya3U-F",
        "outputId": "08b3f4db-795f-46f9-c38f-d36c6ec2f430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: -0.525\n",
            "Subjectivity: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"God exist in the universe, What a boon.\"\n",
        "blob = TextBlob(text)\n",
        "print(\"Polarity:\", blob.sentiment.polarity)\n",
        "print(\"Subjectivity:\", blob.sentiment.subjectivity)"
      ],
      "metadata": {
        "id": "RhHz5Dkp3XNS",
        "outputId": "1ca2555d-f7b1-4f9f-a3bc-93b369499827",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.0\n",
            "Subjectivity: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy\n",
        "#Reading training, test and sample data files\n",
        "training= pd.read_csv('train.csv')\n",
        "\n",
        "training.head()"
      ],
      "metadata": {
        "id": "Pe5vJAZC3jdL",
        "outputId": "19c81b05-d949-4701-8072-3cf216b20311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xf1 in position 28845: invalid continuation byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3369882337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Reading training, test and sample data files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf1 in position 28845: invalid continuation byte"
          ]
        }
      ]
    }
  ]
}